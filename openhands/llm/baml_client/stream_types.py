# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

import typing
import typing_extensions
from pydantic import BaseModel, ConfigDict

import baml_py

from . import types

StreamStateValueT = typing.TypeVar('StreamStateValueT')
class StreamState(BaseModel, typing.Generic[StreamStateValueT]):
    value: StreamStateValueT
    state: typing_extensions.Literal["Pending", "Incomplete", "Complete"]
# #########################################################################
# Generated classes (11)
# #########################################################################

class Choice(BaseModel):
    index: typing.Optional[int] = None
    message: typing.Optional["Message"] = None
    finish_reason: typing.Optional[str] = None

class FormattedLLMRequest(BaseModel):
    conversation: typing.Optional[str] = None
    temperature: typing.Optional[float] = None
    max_tokens: typing.Optional[int] = None
    top_p: typing.Optional[float] = None
    top_k: typing.Optional[float] = None
    seed: typing.Optional[int] = None
    stop: typing.Optional[typing.List[str]] = None

class FormattedMessage(BaseModel):
    role: typing.Optional[typing.Union[str, str, str, str]] = None
    content: typing.Optional[str] = None

class ImageContent(BaseModel):
    type: typing.Optional[str] = None
    image_url: typing.Dict[str, str]
    cache_control: typing.Optional[typing.Dict[str, str]] = None

class LLMCompletionRequest(BaseModel):
    messages: typing.List["Message"]
    tools: typing.Optional[typing.List["Tool"]] = None
    temperature: typing.Optional[float] = None
    max_tokens: typing.Optional[int] = None
    top_p: typing.Optional[float] = None
    top_k: typing.Optional[float] = None
    seed: typing.Optional[int] = None
    stop: typing.Optional[typing.List[str]] = None

class LLMCompletionResponse(BaseModel):
    id: typing.Optional[str] = None
    choices: typing.List["Choice"]
    usage: typing.Optional["Usage"] = None
    model: typing.Optional[str] = None
    created: typing.Optional[int] = None

class Message(BaseModel):
    role: typing.Optional[typing.Union[str, str, str, str]] = None
    content: typing.List[typing.Union["TextContent", "ImageContent"]]
    tool_calls: typing.Optional[typing.List[typing.Dict[str, str]]] = None
    tool_call_id: typing.Optional[str] = None
    name: typing.Optional[str] = None

class Resume(BaseModel):
    name: typing.Optional[str] = None
    email: typing.Optional[str] = None
    experience: typing.List[str]
    skills: typing.List[str]

class TextContent(BaseModel):
    type: typing.Optional[str] = None
    text: typing.Optional[str] = None
    cache_control: typing.Optional[typing.Dict[str, str]] = None

class Tool(BaseModel):
    type: typing.Optional[str] = None
    function_def: typing.Dict[str, str]

class Usage(BaseModel):
    prompt_tokens: typing.Optional[int] = None
    completion_tokens: typing.Optional[int] = None
    total_tokens: typing.Optional[int] = None
    prompt_tokens_details: typing.Optional[typing.Dict[str, str]] = None

# #########################################################################
# Generated type aliases (1)
# #########################################################################


Content: typing_extensions.TypeAlias = typing.Optional[typing.Union["TextContent", "ImageContent"]]
